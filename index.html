<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv='cache-control' content='no-cache'>
    <meta http-equiv='expires' content='0'>
    <meta http-equiv='pragma' content='no-cache'>
    <title>A Comparison of Embedding Models in Semantic Similarity Tasks for Software Engineering</title>
    <link rel="stylesheet" href="styles.css?v=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo">Capstone Project</div>
            <ul class="nav-links">
                <li><a href="#project-info">Project Info</a></li>
                <li><a href="#abstract">Abstract</a></li>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#objectives">Objectives</a></li>
                <li><a href="#concepts">Concepts</a></li>
                <li><a href="#methods">Methods</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#references">References</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section id="hero">
            <div class="hero-content">
                <h1>A Comparison of Embedding Models in Semantic Similarity Tasks for Software Engineering</h1>
                <div class="hero-meta">
                    <p class="hero-author"><i class="fas fa-user-graduate"></i> Vinícius Henrique Ferraz Lima</p>
                    <p class="hero-supervisor"><i class="fas fa-chalkboard-teacher"></i> Supervisor: Arthur Pilone Maia da Silva</p>
                    <p class="subtitle">Capstone Project Report - University of São Paulo, 2025</p>
                </div>
                <div class="hero-buttons">
                    <a href="tese.pdf" class="btn primary" download><i class="fas fa-download"></i> Download Thesis</a>
                    <a href="#abstract" class="btn secondary">Read Abstract</a>
                    <a href="https://gitlab.com/ArthurPilone/deepermatcher" class="btn secondary" target="_blank"><i class="fab fa-gitlab"></i> View Source Code</a>
                </div>
            </div>
        </section>

        <section id="project-info" class="content-section">
            <div class="content-box project-info-box">
                <div class="info-grid">
                    <div class="info-item">
                        <h3><i class="fas fa-user-graduate"></i> Student</h3>
                        <p>Vinícius Henrique Ferraz Lima</p>
                    </div>
                    <div class="info-item">
                        <h3><i class="fas fa-chalkboard-teacher"></i> Supervisor</h3>
                        <p>Arthur Pilone Maia da Silva</p>
                    </div>
                    <div class="info-item">
                        <h3><i class="fas fa-user-tie"></i> Co-supervisor</h3>
                        <p>Prof. Paulo Roberto Miranda Meirelles</p>
                    </div>
                    <div class="info-item">
                        <h3><i class="fas fa-university"></i> Institution</h3>
                        <p>University of São Paulo<br>Institute of Mathematics, Statistics, and Computer Science<br>Bachelor of Computer Science</p>
                    </div>
                </div>
                
                <div class="title-section">
                    <h2><i class="fas fa-book"></i> Title</h2>
                    <p class="thesis-title">A Comparison of Embedding Models in Semantic Similarity Tasks for Software Engineering</p>
                </div>

                <div class="links-section">
                    <h2><i class="fas fa-link"></i> Resources</h2>
                    <div class="resource-links">
                        <a href="tese.pdf" class="resource-link" download>
                            <i class="fas fa-file-pdf"></i>
                            <span>Download Thesis (PDF)</span>
                        </a>
                        <a href="https://gitlab.com/ArthurPilone/deepermatcher" class="resource-link" target="_blank">
                            <i class="fab fa-gitlab"></i>
                            <span>View Source Code</span>
                        </a>
                    </div>
                </div>
            </div>
        </section>

        <section id="abstract" class="content-section">
            <h2>Abstract</h2>
            <div class="content-box">
                <p>Embedding models have been widely used in Natural Language Processing (NLP) tasks to represent texts in vector spaces that capture their semantic relationships. Despite the emergence of different architectures and training techniques, it is presumed that, in certain tasks, these models exhibit similar performance. This work investigates this hypothesis through a systematic comparison of different embedding models applied to semantic textual similarity tasks. From the experiments conducted, we seek to understand whether differences between models used widely in the market are relevant for practical applications. The results contribute to a better understanding of the real impact of choosing embedding models in NLP applications.</p>
                <p style="margin-top: 1.5rem; padding-top: 1.5rem; border-top: 2px solid var(--border-color);"><strong>Keywords:</strong> Embeddings. Semantic Similarity. Natural Language Processing. Vectorial Representation of Text. Model Evaluation.</p>
            </div>
        </section>

        <section id="introduction" class="content-section">
            <h2>Introduction</h2>
            <div class="content-box">
                <p>In recent years, advances in Natural Language Processing (NLP) and Artificial Intelligence (AI) have transformed the way researchers and industry professionals analyze, retrieve, and relate textual information. Central to these advances are embedding models, which are mathematical representations that encode the semantic meaning of text into numerical vectors. These representations serve as the backbone of modern retrieval, classification, and generation systems, enabling more semantic driven interpretations of human language than traditional keyword-based or statistical methods.</p>
                <br>
                <p>As embedding models have matured, a growing body of research in software engineering has adopted them to address complex tasks such as duplicate bug report detection, vulnerability discovery, source code analysis, and requirements traceability. These studies consistently demonstrate that embeddings capture semantic and contextual relationships that would be difficult or impossible to model through handcrafted rules or surface-level text matching.</p>
                <br>
                <p>This work investigates whether the choice of embedding model significantly influences the performance of semantic similarity tasks in software engineering, specifically in the context of matching user reviews with development issues. Through a systematic comparison of five embedding models (Jina, OpenAI Large, OpenAI Small, Gemini, and Cohere) across four software projects, we address the fundamental question: to what extent does the choice of embedding model actually influence the final outcomes of a given task?</p>
            </div>
        </section>

        <section id="objectives" class="content-section">
            <h2>Objectives</h2>
            <div class="content-box">
                <p>This research project aimed to investigate the use of embedding models in semantic similarity tasks for software engineering, specifically focusing on matching user reviews with development issues. The main objectives were:</p>
                <ul style="margin-top: 1rem; padding-left: 2rem;">
                    <li>Compare the performance of five different embedding models (Jina, OpenAI Large, OpenAI Small, Gemini, and Cohere) in semantic textual similarity tasks</li>
                    <li>Evaluate how these models perform across different software projects and relevance levels</li>
                    <li>Understand whether differences between widely-used embedding models are relevant for practical applications</li>
                    <li>Analyze the semantic space organization through visualization techniques (t-SNE)</li>
                    <li>Provide empirical evidence on model selection for semantic similarity tasks in software engineering</li>
                </ul>
            </div>
        </section>

        <section id="concepts" class="content-section">
            <h2>Concepts</h2>
            <div class="content-box">
                <h3>Embedding Models</h3>
                <p>Embedding models are mathematical representations that encode the semantic meaning of text into numerical vectors. These models transform text into dense vector representations in a high-dimensional space where semantically similar texts are located close to one another. This enables machine learning algorithms to understand semantic relationships and perform tasks such as similarity computation, retrieval, and classification.</p>
                <br>
                <h3>Semantic Textual Similarity (STS)</h3>
                <p>Semantic Textual Similarity is a task that measures how semantically similar two pieces of text are, typically on a scale from 0 (completely unrelated) to 1 (semantically equivalent). In software engineering, STS can be used to match user reviews with development issues, identify duplicate bug reports, or find related documentation.</p>
                <br>
                <h3>t-SNE Visualization</h3>
                <p>t-Distributed Stochastic Neighbor Embedding (t-SNE) is a dimensionality reduction technique used to visualize high-dimensional data in two or three dimensions. It preserves local neighborhood structures, making it useful for understanding how embedding models organize semantic space and identify clusters of similar texts.</p>
            </div>
        </section>

        <section id="methods" class="content-section">
            <h2>Methods</h2>
            <div class="content-box">
                <h3>Dataset</h3>
                <p>The research utilized real-world data from four software projects: WordPress Android, Mindustry, K9 Mail (fsck_k9), and PPSSPP. The dataset consisted of user reviews and development issues that were matched and evaluated by human annotators.</p>
                <br>
                <h3>Embedding Models</h3>
                <p>Five embedding models were systematically compared:</p>
                <ul style="margin-top: 0.5rem; padding-left: 2rem;">
                    <li><strong>Jina:</strong> A general-purpose embedding model</li>
                    <li><strong>OpenAI Large:</strong> OpenAI's larger embedding model</li>
                    <li><strong>OpenAI Small:</strong> OpenAI's smaller, more efficient embedding model</li>
                    <li><strong>Gemini:</strong> Google's Gemini embedding model</li>
                    <li><strong>Cohere:</strong> Cohere's embedding model</li>
                </ul>
                <br>
                <h3>Similarity Computation</h3>
                <p>Similarity scores were computed using cosine similarity between embedding vectors of issue-review pairs. The results were compared against human-assigned relevance levels (0-5) to evaluate model performance.</p>
                <br>
                <h3>Visualization</h3>
                <p>t-SNE was used to visualize the semantic space organization, revealing how different models structure the relationships between issues and reviews in the embedding space.</p>
            </div>
        </section>

        <section id="results" class="content-section">
            <h2>Main Findings</h2>
            <div class="content-box">
                <h3>Key Results</h3>
                <p>Our analysis reveals a nuanced answer: while embedding models show remarkable convergence at the extremes of the relevance spectrum, they exhibit meaningful differences at intermediate levels and in overall similarity score distributions.</p>
                <br>
                <h3>Convergence at Extremes</h3>
                <p>At the extremes—clearly irrelevant pairs (Level 0) and highly relevant pairs (Level 5)—all five models produce comparable results. This convergence suggests that when semantic relationships are unambiguous, different embedding models capture similar patterns.</p>
                <br>
                <h3>Differences at Intermediate Levels</h3>
                <p>At intermediate relevance levels (Levels 2-3), significant differences emerge. Jina and OpenAI Large consistently assign higher similarity scores to moderately relevant pairs, while Gemini and Cohere tend to be more conservative, requiring stronger semantic signals before assigning positive similarity scores.</p>
                <br>
                <h3>Model Performance Patterns</h3>
                <p>Across all projects, Gemini and Jina consistently outperform other models in terms of both median similarity scores and consistency. Cohere shows a more conservative approach that may reduce false positives but potentially increase false negatives.</p>
                <br>
                <h3>Semantic Space Organization</h3>
                <p>t-SNE visualizations confirm that all models successfully separate issues and reviews into distinct clusters. OpenAI models produce more compact, well-defined clusters, while Jina and Cohere show more diffuse distributions.</p>
                <br>
                <h3>Practical Implications</h3>
                <p>The findings suggest that model selection matters most when dealing with ambiguous or borderline cases. For strongly relevant or clearly irrelevant pairs, the choice of embedding model appears to have less impact. Practitioners should carefully consider their tolerance for false positives and false negatives when selecting an embedding model.</p>
            </div>
        </section>

        <section id="references" class="content-section">
            <h2>References</h2>
            <div class="content-box">
                <div class="reference">
                    <p>[1] Jurafsky, D.; Martin, J. H. (2023). Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition (3rd ed.). Pearson.</p>
                    <a href="https://web.stanford.edu/~jurafsky/slp3/" class="reference-link" target="_blank">View Book</a>
                </div>

                <div class="reference">
                    <p>[2] Pilone, A.; Raglianti, M.; Lanza, M.; Kon, F.; Meirelles, P. (2025). "Automatically augmenting GitHub issues with informative user reviews". In: 2025 IEEE International Conference on Software Maintenance and Evolution (ICSME).</p>
                </div>

                <div class="reference">
                    <p>[3] Li, J.; Li, M.; Liu, Y.; Zhang, L.; Wang, Y. (2024). "HYDBre: a hybrid retrieval method for detecting duplicate software bug reports". In: Proceedings of the 2024 IEEE International Conference on Software Maintenance and Evolution, pp. 1-12.</p>
                    <a href="https://ieeexplore.ieee.org/document/10818310/" class="reference-link" target="_blank">View Paper</a>
                </div>

                <div class="reference">
                    <p>[4] Vaswani, A. et al. (2017). "Attention is all you need". Advances in Neural Information Processing Systems 30.</p>
                </div>

                <div class="reference">
                    <p>[5] Tripathy, B. K.; Anveshrithaa, S.; Ghela, S. (2021). "T-distributed stochastic neighbor embedding (t-sne)". In: Data Science and Innovations for Intelligent Systems. CRC Press, p. 13.</p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="footer-content">
            <p>&copy; 2025 Vinícius Henrique Ferraz Lima. All rights reserved.</p>
            <p style="margin-top: 0.5rem; font-size: 0.9rem;">This work is published under the CC BY 4.0 license (Creative Commons Attribution 4.0 International License)</p>
            <div class="social-links">
                <a href="https://github.com/viniciusfl"><i class="fab fa-github"></i></a>
                <a href="https://www.linkedin.com/in/vinicius-ferraz-lima/"><i class="fab fa-linkedin"></i></a>
                <a href="mailto:viniciushenrique2301@gmail.com"><i class="fas fa-envelope"></i></a>
            </div>
        </div>
    </footer>

    <script src="script.js?v=1.0"></script>
</body>
</html> 